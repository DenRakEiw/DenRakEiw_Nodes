#!/usr/bin/env python3
"""
üîç PRE-TRAINING CHECKER
F√ºhrt ALLE kritischen Pr√ºfungen vor dem Training durch:
- VAE-Authentizit√§t
- Dataset-Qualit√§t  
- Latent-Validierung
- Vorher-Nachher Paare
- Visual Tests
"""

import os
import sys
import torch
from validation_system import run_complete_validation
from dataset_preparation import LatentDatasetCreator

def check_system_requirements():
    """Pr√ºfe System-Anforderungen"""
    print("üîß SYSTEM-ANFORDERUNGEN PR√úFEN")
    print("=" * 40)
    
    # GPU Check
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name()
        vram = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"‚úÖ GPU: {gpu_name}")
        print(f"‚úÖ VRAM: {vram:.1f} GB")
        
        if vram < 6:
            print("‚ö†Ô∏è WARNUNG: Wenig VRAM! Empfohlen: 8GB+")
            print("   Reduziere batch_size auf 8 oder weniger")
        
        return True
    else:
        print("‚ùå KEINE GPU GEFUNDEN!")
        print("üö® Training auf CPU wird SEHR langsam sein!")
        response = input("Trotzdem fortfahren? (y/n): ").lower()
        return response == 'y'

def check_disk_space():
    """Pr√ºfe verf√ºgbaren Speicherplatz"""
    print("\nüíæ SPEICHERPLATZ PR√úFEN")
    print("=" * 40)

    try:
        # Windows-kompatible Speicherplatz-Pr√ºfung
        import shutil
        free_space_gb = shutil.disk_usage('.').free / (1024**3)

        print(f"üíæ Verf√ºgbarer Speicher: {free_space_gb:.1f} GB")

        required_space = 15  # GB f√ºr Datasets + Models

        if free_space_gb < required_space:
            print(f"‚ùå NICHT GENUG SPEICHER!")
            print(f"   Ben√∂tigt: {required_space} GB")
            print(f"   Verf√ºgbar: {free_space_gb:.1f} GB")
            return False

        print(f"‚úÖ Genug Speicher verf√ºgbar")
        return True

    except Exception as e:
        print(f"‚ö†Ô∏è Speicherplatz-Pr√ºfung fehlgeschlagen: {e}")
        print("‚úÖ Fahre trotzdem fort...")
        return True

def check_internet_connection():
    """Pr√ºfe Internet-Verbindung f√ºr Downloads"""
    print("\nüåê INTERNET-VERBINDUNG PR√úFEN")
    print("=" * 40)
    
    try:
        import requests
        response = requests.get("https://huggingface.co", timeout=10)
        if response.status_code == 200:
            print("‚úÖ Internet-Verbindung OK")
            print("‚úÖ Hugging Face erreichbar")
            return True
        else:
            print(f"‚ö†Ô∏è Hugging Face nicht erreichbar: {response.status_code}")
            return False
    except Exception as e:
        print(f"‚ùå Internet-Verbindung FEHLER: {e}")
        print("üö® Ohne Internet k√∂nnen keine Modelle/Datasets geladen werden!")
        return False

def check_existing_datasets():
    """Pr√ºfe existierende Datasets"""
    print("\nüìä EXISTIERENDE DATASETS PR√úFEN")
    print("=" * 40)
    
    train_dir = "datasets/latents/train"
    val_dir = "datasets/latents/validation"
    
    train_exists = os.path.exists(train_dir)
    val_exists = os.path.exists(val_dir)
    
    if train_exists:
        train_files = len([f for f in os.listdir(train_dir) if f.endswith('.pt')])
        print(f"‚úÖ Training Dataset: {train_files} Latents")
    else:
        print("‚ö†Ô∏è Training Dataset nicht gefunden")
        train_files = 0
    
    if val_exists:
        val_files = len([f for f in os.listdir(val_dir) if f.endswith('.pt')])
        print(f"‚úÖ Validation Dataset: {val_files} Latents")
    else:
        print("‚ö†Ô∏è Validation Dataset nicht gefunden")
        val_files = 0
    
    if train_files < 100:
        print("‚ö†Ô∏è Wenige Training-Samples! Empfohlen: 500+")
        print("   Kleinere Datasets k√∂nnen zu Overfitting f√ºhren")
    
    if val_files < 10:
        print("‚ö†Ô∏è Wenige Validation-Samples! Empfohlen: 50+")
    
    return train_exists and val_exists and train_files > 0 and val_files > 0

def create_datasets_if_needed():
    """Erstelle Datasets falls n√∂tig"""
    print("\nüìä DATASET-ERSTELLUNG")
    print("=" * 40)
    
    if not check_existing_datasets():
        print("üì• Erstelle neue Datasets...")
        
        try:
            creator = LatentDatasetCreator()
            train_dir, val_dir = creator.create_training_dataset(target_size=1000)
            print("‚úÖ Datasets erfolgreich erstellt!")
            return True
        except Exception as e:
            print(f"‚ùå Dataset-Erstellung FEHLGESCHLAGEN: {e}")
            return False
    else:
        print("‚úÖ Datasets bereits vorhanden")
        return True

def run_comprehensive_check():
    """F√ºhre umfassende Pre-Training Checks durch"""
    print("üîç UMFASSENDE PRE-TRAINING PR√úFUNG")
    print("=" * 60)
    print("Diese Pr√ºfung stellt sicher, dass:")
    print("‚úÖ Echte Stability AI VAE verwendet wird (keine Fakes!)")
    print("‚úÖ Datasets korrekt erstellt wurden")
    print("‚úÖ Latents g√ºltig sind")
    print("‚úÖ Vorher-Nachher Paare funktionieren")
    print("‚úÖ System bereit f√ºr Training ist")
    print("=" * 60)
    
    checks_passed = 0
    total_checks = 5
    
    # 1. System-Anforderungen
    if check_system_requirements():
        checks_passed += 1
        print("‚úÖ Check 1/5: System-Anforderungen")
    else:
        print("‚ùå Check 1/5: System-Anforderungen FEHLGESCHLAGEN")
        return False
    
    # 2. Speicherplatz
    if check_disk_space():
        checks_passed += 1
        print("‚úÖ Check 2/5: Speicherplatz")
    else:
        print("‚ùå Check 2/5: Speicherplatz FEHLGESCHLAGEN")
        return False
    
    # 3. Internet
    if check_internet_connection():
        checks_passed += 1
        print("‚úÖ Check 3/5: Internet-Verbindung")
    else:
        print("‚ùå Check 3/5: Internet-Verbindung FEHLGESCHLAGEN")
        return False
    
    # 4. Datasets
    if create_datasets_if_needed():
        checks_passed += 1
        print("‚úÖ Check 4/5: Datasets")
    else:
        print("‚ùå Check 4/5: Datasets FEHLGESCHLAGEN")
        return False
    
    # 5. Vollst√§ndige Validierung
    print("\nüîç FINALE VALIDIERUNG...")
    if run_complete_validation():
        checks_passed += 1
        print("‚úÖ Check 5/5: Vollst√§ndige Validierung")
    else:
        print("‚ùå Check 5/5: Vollst√§ndige Validierung FEHLGESCHLAGEN")
        return False
    
    # Ergebnis
    print("\n" + "=" * 60)
    print(f"üéâ ALLE CHECKS ERFOLGREICH! ({checks_passed}/{total_checks})")
    print("‚úÖ SYSTEM BEREIT F√úR TRAINING!")
    print("=" * 60)
    
    # Training-Empfehlungen
    print("\nüöÄ TRAINING-EMPFEHLUNGEN:")
    
    if torch.cuda.is_available():
        vram = torch.cuda.get_device_properties(0).total_memory / 1e9
        if vram >= 12:
            print("   batch_size = 32 (hohe VRAM)")
        elif vram >= 8:
            print("   batch_size = 16 (mittlere VRAM)")
        else:
            print("   batch_size = 8 (niedrige VRAM)")
    else:
        print("   batch_size = 4 (CPU)")
    
    print("   epochs = 200 (f√ºr beste Qualit√§t)")
    print("   learning_rate = 1e-4 (bew√§hrt)")
    
    return True

def main():
    """Hauptfunktion"""
    print("üîç PRE-TRAINING CHECKER")
    print("Dieser Check stellt sicher, dass alles f√ºr das Training bereit ist.")
    print()
    
    if run_comprehensive_check():
        print("\nüöÄ BEREIT F√úR TRAINING!")
        print("Starte das Training mit:")
        print("   python train_advanced_upscaler.py")
        print("oder:")
        print("   python quick_start_training.py")
    else:
        print("\n‚ùå TRAINING NICHT M√ñGLICH!")
        print("Behebe die Probleme und f√ºhre den Check erneut aus.")
        sys.exit(1)

if __name__ == "__main__":
    main()
